{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMNIST-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k1f8C6IivG3z",
        "ooZeazNbvgm0",
        "V65UGX3ewGPR",
        "4sBskJLVxQ5I",
        "r0O0-MKAxyY3",
        "28JPo7I2x8Sd",
        "lPaEpjRE23bf",
        "LYiumYJs3NAk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e99edfad82e749f2a280cd3fa90d4061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63f41bb52b6b469fa378b9401c73ecee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01e00f6fba1745c9ac1ddf19f8665bcc",
              "IPY_MODEL_f93ffbba79b94cb79b25356d4a79c91c"
            ]
          }
        },
        "63f41bb52b6b469fa378b9401c73ecee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01e00f6fba1745c9ac1ddf19f8665bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4bb199c98a44d9eacaa5e90ea674e91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94f8e3853e7c4d1ca5fad30478b6c5e6"
          }
        },
        "f93ffbba79b94cb79b25356d4a79c91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d7ac30b34eec4200bb9f7ae332d59b5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 561758208/? [00:29&lt;00:00, 35084451.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82137da38f15496295a4ae724c34e820"
          }
        },
        "d4bb199c98a44d9eacaa5e90ea674e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94f8e3853e7c4d1ca5fad30478b6c5e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7ac30b34eec4200bb9f7ae332d59b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82137da38f15496295a4ae724c34e820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKJ49Pdgptnm",
        "colab_type": "text"
      },
      "source": [
        "# Using Feed-forwarding Neural Network to classify the EMNIST Dataset\n",
        "\n",
        "PyTorch provides a wide range of built-in datasets to work on like, MNIST, EMNIST, Fashion MNIST, CIFAR10 etc. In this notebook, we are using the EMNIST dataset which is split into 6 sub-datasets. We will be using the 'letters' sub-dataset, which consists of 26 balanced classes, each having 28x28 pixel images of hand-written letters from the english alphabet. The objective of the model is Hand-written Alphabet Recognition.\n",
        "\n",
        "We'll be training the model on 124800 images from the training dataset, out of which 1% of the images will be used for the validation set, and the model will be tested on 20800 images from the test dataset.\n",
        "\n",
        "In the model, we'll create hidden layers, that pass 'feed' from the previous layer to the next layer, hence, feed-forwarding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoQa1JOrAh0",
        "colab_type": "text"
      },
      "source": [
        "#### Importing libraries and the EMNIST dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7zr1jQornk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import EMNIST"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2A99Nfrlxt",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading the EMNIST dataset to the notebook\n",
        "The root directory where we want the dataset to be downloaded, the sub-dataset and the download permissions are to be passed as arguments to get the in-built dataset to work on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyRiDRYNpDG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "e99edfad82e749f2a280cd3fa90d4061",
            "63f41bb52b6b469fa378b9401c73ecee",
            "01e00f6fba1745c9ac1ddf19f8665bcc",
            "f93ffbba79b94cb79b25356d4a79c91c",
            "d4bb199c98a44d9eacaa5e90ea674e91",
            "94f8e3853e7c4d1ca5fad30478b6c5e6",
            "d7ac30b34eec4200bb9f7ae332d59b5a",
            "82137da38f15496295a4ae724c34e820"
          ]
        },
        "outputId": "720f9e22-a823-47e6-bc8c-702419f8f4c9"
      },
      "source": [
        "dataset = EMNIST(root='data/', split='letters', download=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting zip archive\n",
            "Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to data/EMNIST/raw/emnist.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e99edfad82e749f2a280cd3fa90d4061",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/EMNIST/raw/emnist.zip to data/EMNIST/raw\n",
            "Processing byclass\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing bymerge\n",
            "Processing balanced\n",
            "Processing letters\n",
            "Processing digits\n",
            "Processing mnist\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2jVHzjatgKw",
        "colab_type": "text"
      },
      "source": [
        "#### Exploring the Dataset\n",
        "Now, to get familiar with the dataset, we'll just look at the length of the dataset, some of the nodes of the dataset and print their image and label for some visual familiarity, and see the classes the dataset is divided into."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b9OHhg-pab0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d9c3f50-4860-4e78-899b-699937c672bf"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v83_HRy78jFz",
        "colab_type": "text"
      },
      "source": [
        "The training dataset contains 124800 data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFYNM2JosapJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d2cb79f-aacc-4db9-8b77-02f221c60c95"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F9AEF548D68>, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtgVoVYQsdTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "185d9188-daf5-44e8-f2ca-0b9fdecee807"
      },
      "source": [
        "dataset[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F9AEE7E1160>, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVhhAvZH82m_",
        "colab_type": "text"
      },
      "source": [
        "The first two datapoints of the training dataset are the letters 'w' (23rd alphabet) and 'g' (7th alphabet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcN8YI9sfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhCvRxuooGkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "6a98b153-e648-4053-ad33-7301d892ae80"
      },
      "source": [
        "classes = dataset.classes\n",
        "classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFiPIp_boUym",
        "colab_type": "text"
      },
      "source": [
        "The 26 classes are all the letters of the english alphabet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXnpJLdFs55S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b1f6f7d8-ea01-4f54-91a3-6cdf7630f010"
      },
      "source": [
        "image, label = dataset[2]\n",
        "label -= 1\n",
        "plt.imshow(image, cmap='gray')\n",
        "print(classes[label])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY_pwNFytCUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8af5bce2-4f1f-4a67-81e2-4b53375f677f"
      },
      "source": [
        "image, label = dataset[3]\n",
        "label -= 1\n",
        "plt.imshow(image, cmap='gray')\n",
        "print(classes[label])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfrEC3OxuCXp",
        "colab_type": "text"
      },
      "source": [
        "#### Transforming the images in the dataset to tensors \n",
        "To work with data points and perform operations on them, we need to convert them to tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O43ev7Utb7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZS2M8g3uA_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff45e400-edaf-473e-8bc2-7618c3f0d9c4"
      },
      "source": [
        "dataset = EMNIST(root='data/', train=True, transform=transforms.ToTensor(), split='letters')\n",
        "len(dataset)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1YShb6zuYna",
        "colab_type": "text"
      },
      "source": [
        "#### Exploring the image tensors\n",
        "Each data point has two parts: the image tensor and it's label.\n",
        "The shape of the image tensor is [1, 28, 28], signifying that it only consists of one channel(lightness channel, L, since it's a grayscale image), conveyed by the first dimension; and the size of the image that 28x28 pixels, as conveyed by the subsequent 2 dimensions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOTWsqPCuXXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "537d546c-96e9-41df-b758-af281251d666"
      },
      "source": [
        "img_tensor, labels = dataset[0]\n",
        "print(img_tensor.shape, labels-1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLwVSGMZuiR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "115c870a-6640-48be-cb5c-2b837ef62472"
      },
      "source": [
        "img_tensor, labels = dataset[1]\n",
        "print(img_tensor.shape, labels-1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9giUOYFrukMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "688657ce-81f3-4065-d6e6-10ee09fe59ce"
      },
      "source": [
        "img_tensor, labels = dataset[2]\n",
        "print(img_tensor, labels-1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.6588, 0.3529,\n",
            "          0.0392, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0039, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0157, 0.0157, 0.0196, 0.4235, 0.9922, 0.9686,\n",
            "          0.8157, 0.5059, 0.5490, 0.7137, 0.5451, 0.5059, 0.6235, 0.4980,\n",
            "          0.4471, 0.1294, 0.0196, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0824, 0.1961, 0.4902, 0.4980, 0.5059, 0.8275, 0.9961, 0.9961,\n",
            "          0.9961, 0.9804, 0.9804, 0.9922, 0.9804, 0.9804, 0.9843, 0.9804,\n",
            "          0.9608, 0.7255, 0.1255, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.1804, 0.4902, 0.5490,\n",
            "          0.9098, 0.9804, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 1.0000, 0.9961,\n",
            "          0.9961, 0.8510, 0.1451, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0314, 0.4510, 0.8000, 0.9608, 0.9922, 0.9608,\n",
            "          0.6745, 0.4980, 0.4980, 0.4980, 0.4980, 0.5059, 0.9255, 0.9961,\n",
            "          0.9255, 0.5059, 0.4980, 0.5059, 0.7961, 0.8510, 0.8510, 0.8510,\n",
            "          0.7216, 0.4706, 0.0706, 0.0000],\n",
            "         [0.0000, 0.0784, 0.6196, 0.9922, 0.9922, 0.6941, 0.4471, 0.1804,\n",
            "          0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.8510, 0.9961,\n",
            "          0.8510, 0.0157, 0.0000, 0.0000, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "          0.0118, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.1451, 0.8431, 0.9961, 0.8667, 0.1412, 0.0157, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.8706, 0.9961,\n",
            "          0.8431, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.1255, 0.7961, 0.9961, 0.5765, 0.0196, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.9804, 0.9647,\n",
            "          0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0157, 0.4510, 0.9961, 0.9804, 0.3922, 0.0824, 0.0118,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.6863, 0.9961, 0.8000,\n",
            "          0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0863, 0.7922, 0.9765, 0.9882, 0.9098, 0.6706,\n",
            "          0.2000, 0.1451, 0.1451, 0.1608, 0.5176, 0.9922, 0.9647, 0.3098,\n",
            "          0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0039, 0.1412, 0.7647, 0.9804, 0.9961, 0.9843,\n",
            "          0.8706, 0.8510, 0.8510, 0.8510, 0.9255, 0.9961, 0.6863, 0.0314,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.1961, 0.6706, 0.9098,\n",
            "          0.9804, 0.9804, 0.9804, 0.9804, 0.9608, 0.6235, 0.0784, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0824,\n",
            "          0.1451, 0.1451, 0.1451, 0.1451, 0.1255, 0.0118, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]) 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpURZB2muwvT",
        "colab_type": "text"
      },
      "source": [
        "#### Why do we need a validation set?\n",
        "We need a validation set to check our model before finally testing it on the test dataset. It helps us to change hyperparameters accordingly to get the best results, and then pick the best version of the model before reporting the final results.\n",
        "\n",
        "#### Create validation set from the training set\n",
        "We take the 1% of the training set as our validation set in this notebook, though any small percentage can be taken. The validation set is created by randomly splitting the training dataset into two parts of suitable size. The random split plays a major role here as, if we split it in order, the training dataset might not have some classes at all, and since the model was never trained for those classes which got divided into the validation set, the model will never be able to guess them. Which means, even after training our model, our model's accuracy on the validation set will always be zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdO1T0osupKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64ffb3c7-b819-4fe5-a7e4-8cb14d0f60d4"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "val_per = 0.1\n",
        "val_len = int(val_per*len(dataset))\n",
        "train_ds, val_ds = random_split(dataset, [len(dataset)-val_len, val_len])\n",
        "print(len(train_ds), len(val_ds))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112320 12480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1f8C6IivG3z",
        "colab_type": "text"
      },
      "source": [
        "#### Load the training and validation data in batches\n",
        "We use the DataLoader to load the training and validation dataset with a batch size of 128 data points. We shuffle the training dataset because the most randomized inputs produce the most general model, which is favourable. However, we do not shuffle the validation dataset as, we cannot compare different evaluations if the dataset on which we are evaluating is not the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkYLpztUu-sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_load = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_load = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooZeazNbvgm0",
        "colab_type": "text"
      },
      "source": [
        "#### Creating a feed-forwarding neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdcDcl61Zjag",
        "colab_type": "text"
      },
      "source": [
        "Since the input and output sizes should be scalar integers for us to implement regression on them, input size can't be in the form of [28, 28], therefore, it is 28*28 = 784 (number of pixels in the image if we flatten the image). And output size is clearly 26, because the image will be classified into one of the 26 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmiMQaokvZH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "input_size = 28*28\n",
        "output_size = 26"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3rfJjGua40P",
        "colab_type": "text"
      },
      "source": [
        "We extend the nn.Module class to define our EmnistModel. It consists of four nn.Linear layers, out of which 3 are called hidden layers, invoked in the forward function after we flatten the input based on its last two dimensions(the dimensions conveying the image size). After implementing the first linear layer, the outputs go through a non-linear activation function, and this repeats till the outputs go through the last linear layer. The size of our hidden layers is 512, 128, 32 respectively.\n",
        "\n",
        "Then we have the training step where we use the cross_entropy loss function on the predictions and targets to calculate the loss for the training dataset. In the validation step, we also calculate the accuracy of the model along with the loss on the validation set.\n",
        "\n",
        "In the last two functions, we combine the validation losses and accuracies after each epoch, so that we can track the progress of the training."
      ]
    },
}
